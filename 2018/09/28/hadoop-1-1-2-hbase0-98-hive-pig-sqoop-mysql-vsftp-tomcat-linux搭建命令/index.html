<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css" integrity="sha256-no0c5ccDODBwp+9hSmV5VvPpKwHCpbVzXHexIkupM6U=" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js" integrity="sha256-a5YRB27CcBwBFcT5EF/f3E4vzIqyHrSR878nseNYw64=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"ceaser.wang","root":"/","images":"/images","scheme":"Muse","version":"8.6.1","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true}}</script><script src="/js/config.js"></script>
<meta name="description" content="一、linux基本操作">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令">
<meta property="og:url" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/index.html">
<meta property="og:site_name" content="南贺神社">
<meta property="og:description" content="一、linux基本操作">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211133642653.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211133723437.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211134053215.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211134124883.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211134209802.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211134249127.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211134326654.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135104291.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135133008.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135208891.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135241062.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135308637.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135343825.png">
<meta property="og:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211135419203.png">
<meta property="article:published_time" content="2018-09-28T20:55:45.000Z">
<meta property="article:modified_time" content="2022-01-04T14:41:25.640Z">
<meta property="article:author" content="CeaserWang">
<meta property="article:tag" content="hadoop hbase hive pig sqoop mysql vsftp tomcat linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/20151211133642653.png">


<link rel="canonical" href="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/","path":"2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux搭建命令/","title":"hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令 | 南贺神社</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">南贺神社</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你写程序有写诗一样的感觉吗?</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">205</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">24</span></a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">212</span></a></li>
        <li class="menu-item menu-item-0xcc"><a href="/0xcc/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>0XCC</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="CeaserWang"
      src="/../0xcc/index/Uchiha.jpg">
  <p class="site-author-name" itemprop="name">CeaserWang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">212</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">205</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLzExNTY3MjE4NzQ=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;1156721874"><i class="fab fa-github fa-fw"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOmNlYXNlcndhbmdAb3V0bG9vay5jb20=" title="E-Mail → mailto:ceaserwang@outlook.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</span>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-user-friends fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly90d29kcmFnb25sYWtlLmNvbQ==" title="https:&#x2F;&#x2F;twodragonlake.com">TwoDragonLake</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9yb290Y2x1c3Rlci5naXRodWIuaW8=" title="https:&#x2F;&#x2F;rootcluster.github.io">RootCluster</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9tdXNlZmxvdy5pbw==" title="https:&#x2F;&#x2F;museflow.io">MuseFlow</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9pbmNvZGVyLm9yZw==" title="https:&#x2F;&#x2F;incoder.org">BladeCode</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9rYWlmYS5kZXY=" title="https:&#x2F;&#x2F;kaifa.dev">Alyenc</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmRhemhpZGF5b25nLmNu" title="https:&#x2F;&#x2F;blog.dazhidayong.cn">Killua</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9qb2NlbHluc2hhbmcuY24v" title="https:&#x2F;&#x2F;jocelynshang.cn&#x2F;">Jocelyn</span>
        </li>
    </ul>
  </div>

          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/../0xcc/index/Uchiha.jpg">
      <meta itemprop="name" content="CeaserWang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="南贺神社">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-09-28 20:55:45" itemprop="dateCreated datePublished" datetime="2018-09-28T20:55:45+00:00">2018-09-28</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2022-01-04 14:41:25" itemprop="dateModified" datetime="2022-01-04T14:41:25+00:00">2022-01-04</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/cloud/" itemprop="url" rel="index"><span itemprop="name">cloud</span></a>
        </span>
    </span>

  
    <span id="/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/" class="post-meta-item leancloud_visitors" data-flag-title="hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><strong>一、linux基本操作</strong></p>
<span id="more"></span>
<pre><code>Linux系统下要和外界进行文件传输需要使用ftp，对此需要搭建ftp服务
</code></pre>
<p><strong>(1)vsftp install :</strong><br>        reference file :/mnt/linuxshare/RHEL 5.2下vsftp配置全教程 - 51CTO.COM.htm<br>        install:<br>        rpm -ivh vsftpd-2.0.5-12.el5.rpm<br>        start:<br>        service vsftpd start<br>        安装完成后，vsftpd配置文件为/etc/vsftpd/vsftpd.conf，通过以下命令可启动vsftpd并将其设置为自动启动。<br>           service vsftpd restart<br>        chkconfig vsftpd on<br>        使用ftp需要关闭防火墙，把Linux的防火墙清空:<br>        iptables -F<br>        service iptables stop<br>        chkconfig iptables off<br><strong>(2)linux cloudy install package（linux云应用安装）</strong><br>    /mnt/linuxshare/epel-release-5-4.noarch.rpm<br><strong>(3)Linux下配置环境变量：</strong><br>        1.修改/etc/profile文件<br>        如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。<br>        (1)用文本编辑器打开/etc/profile<br>        (2)在profile文件末尾加入：<br>        JAVA_HOME=/usr/share/jdk1.5.0_05<br>        PATH=$JAVA_HOME/bin:$PATH<br>        CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>        export JAVA_HOME<br>        export PATH<br>        export CLASSPATH</p>
<pre><code>    一、linux基本操作
    Linux系统下要和外界进行文件传输需要使用ftp，对此需要搭建ftp服务
    (1)vsftp install :
    reference file :/mnt/linuxshare/RHEL 5.2下vsftp配置全教程 - 51CTO.COM.htm
    install:
    rpm -ivh vsftpd-2.0.5-12.el5.rpm
    start:
    service vsftpd start
    安装完成后，vsftpd配置文件为/etc/vsftpd/vsftpd.conf，通过以下命令可启动vsftpd并将其设置为自动启动。
       service vsftpd restart
    chkconfig vsftpd on
    使用ftp需要关闭防火墙，把Linux的防火墙清空:
    iptables -F
    service iptables stop
    chkconfig iptables off
    (2)linux cloudy install package（linux云应用安装）
    /mnt/linuxshare/epel-release-5-4.noarch.rpm
    (3)Linux下配置环境变量：
    1.修改/etc/profile文件
    如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
    (1)用文本编辑器打开/etc/profile
    (2)在profile文件末尾加入：
    JAVA_HOME=/usr/share/jdk1.5.0_05
    PATH=$JAVA_HOME/bin:$PATH
    CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
    export JAVA_HOME
    export PATH
    export CLASSPATH
</code></pre>
<p> <strong>(4)jdk的安装与卸载</strong><br>            <strong>jdk卸载</strong><br>            卸载默认的：<br>            用root用户登陆到系统，打开一个终端输入<br>             rpm -qa|grep gcj<br>            显示内容其中包含下面两行信息<br>             java-1.4.2-gcj-compat-1.4.2.0-27jpp<br>             java-1.4.2-gcj-compat-devel-l.4.2.0-27jpp<br>            卸载<br>             rpm -e java-1.4.2-gcj-compat-devel-l.4.2.0-27jpp<br>             rpm -e java-1.4.2-gcj-compat-l.4.2.0-27jpp<br>            卸载其他自己安装的JDK就直接用rpm -e <javaXXXXX><br>       <strong>卸载rpm版的jdk：</strong><br>               #rpm -qa|grep jdk<br>               显示：jdk-1.6.0_10-fcs<br>               卸载：#rpm -e  –nodeps  jdk-1.6.0_10-fcs</p>
<p><strong>(5)设置环境变量汇总</strong></p>
<pre><code>            1、/etc/profile设置环境变量
            a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
            b. linux下用冒号“:”来分隔路径
            c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值,在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种常见的错误。
            d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
            e. export是把这三个变量导出为全局变量。
            f. 大小写必须严格区分。

            2. 修改.bashrc文件　　
            这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
            (1)用文本编辑器打开用户目录下的.bashrc文件
            (2)在.bashrc文件末尾加入：　　
            set JAVA_HOME=/usr/java/jdk1.7.0_55
            export JAVA_HOME
            set PATH=$JAVA_HOME/bin:$PATH
            export PATH
            set CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
            export CLASSPATH
            (3)重新登录

            3. 直接在shell下设置变量
            不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
            只需在shell终端执行下列命令：
            export JAVA_HOME=/usr/java/jdk1.7.0_55
            export PATH=$JAVA_HOME/bin:$PATH
            export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</code></pre>
<p><strong>(6)压缩包的压缩与解压与其他</strong><br>            tar -zxvf apache-tomcat-6.0.39.tar.gz<br>            gzip -d apache-tomcat-6.0.39.tar.gz<br>              查看当前进程<br>            ps -ef|grep tomcat<br><strong>(7)杀死进程</strong><br>             kill -9 idnum<br>            命令行上网<br>            wget <span class="exturl" data-url="aHR0cDovLzE5Mi4xNjguMS4xMjYv">http://192.168.1.126<i class="fa fa-external-link-alt"></i></span><br>            rpm的查看与卸载<br>            rpm: redhat package management<br>            rpm -qa|grep jdk 查看linux安装的包<br>            rpm -e 包名 卸载<br><strong>(7)小结</strong><br>            /etc/profile  有用户登陆设置环境变量（命令：source /etc/profile 可以让设置生效）<br>            /etc/bashrc  设置的命令 如果一有用户登陆就执行初始化脚本。<br>            /home/wzq(用户)  .bash_profile为单独的用户设置环境变量<br>            /home/wzq(用户)  .bashrc 为单独的用户登录时执行的脚本（执行的程序）<br>            /etc/rc.local    开机启动执行的脚本<br>            举例tomcat：<br>            JAVA_HOME=/usr/java/jdk1.7.0_55<br>            PATH=$JAVA_HOME/bin:$PATH<br>            CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>            export JAVA_HOME<br>            export PATH<br>            export CLASSPATH<br>            启动：/tomcat6/bin/startup.sh</p>
<pre><code>    mysqladmin -u root password &quot;operater&quot;  设置mysql密码
    启动mysql：
    service mysql start
    开机启动：
    chkconfig iptables on

    注意：
    修改MySQL数据库root用户的初始密码，先查下初始密码
    [root@vmoel5u4 mysql_installer]# vi /root/.mysql_secret
    设置初始密码即可
</code></pre>
<p><strong>(8)修改主机名</strong></p>
<pre><code>修改当前回话的主机名：hostname hadoop
永久修改主机名文件所在目录：vi /etc/sysconfig/network
ip和主机名绑定：vi /etc/hosts  加入一行：
10.164.10.100 hadoop
重启网卡：service network restart
测试：ping hadoop
</code></pre>
<p><strong>(9)SSH的免密码登陆：</strong><br>        ssh-keygen -t rsa 生成秘钥文件<br>        cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys<br>        注意：此处一定要设置，不然jobtracker无法启动！！！另外可以把所有机器上的所有authorized_keys收集起来放在一个大的authorized_keys文件里边，然后用这个大的文件分别覆盖<br>        所有机器的authorized_keys文件，可以实现所有机器之间的免密码登陆。<br>        hadoop环境搭建<br><strong>（10）hadoop设置环境变量</strong><br>        /etc/profile<br>        export JAVA_HOME=/usr/java/jdk1.7.0_55<br>        export HADOOP_HOME=/usr/hadoop<br>        export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH<br>        export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>        export JAVA_HOME<br>        export PATH<br>        export CLASSPATH<br><strong>（11）修改配置</strong><br>        修改$HADOOP_HOME_HOME/conf下的hadoop-env.sh、core-site.xml、hdfs-site.xml、mapred-site.xml<br>        细节见文档<br>        非伪分布特殊配置<br>        config/masters  文件里边配置jobtracker所在节点所在机器<br>        config/slaves   文件里边配置datanode和tasktracker所在节点的机器<br><strong>（12）hadoop格式化</strong><br>            hadoop namenode -format<br>            windows/linux下查看进程的命令：jps<br><strong>(13)启动hadoop:start-all.sh   启动5个java进程如下</strong><br>            5500 JobTracker<br>            4660 NameNode<br>            4251 Bootstrap<br>            4914 SecondaryNameNode<br>            5659 Jps<br>            4774 DataNode<br>            5091 TaskTracker<br>            验证：<br>            linux下浏览器，hadoop:50070(namaeNode),hadoop:50030(jobTracker)<br>            windows下验证需要绑定主机名：修改文件路径如下：<br>            C:\Windows\System32\drivers\etc\hosts文件<br>            加入一行：192.168.1.123 hadoop</p>
<p><strong>（14）Warning: $HADOOP_HOME is deprecated.的修改</strong><br>            加入一行：export HADOOP_HOME_WARN_SUPPRESS=1</p>
<p><strong>（15）hadoop复制</strong><br>            scp -r 源文件路径:目标文件路径 （配置好SSH免密码登陆）<br>            export HADOOP_ROOT_LOGGER=DEBUG,console<br><strong>（16）hdfs文件系统操作命令;</strong><br>        hadoop fs -ls  / :根目录下的数据<br>        hadoop fs -lsr  / :根目录下的数据(递归查看)<br>        hadoop fs -mkdir /d1:在HDFS下创建文件夹<br>        hadoop fs -put /root/install.log(linux文件路径) /usr/d1 : 从linux上传文件到HDFS文件系统目录（文件夹d1存在，如果不存在，那么上传后install.log的文件名为d1）<br>        hadoop fs -get /usr/d1/install.log（HDFS文件系统路径） /home/wzq/copyinstall.log:  下载到linux的/home/wzq文件夹下 并且改名为copyinstall.log<br>        hadoop fs -get /usr/d1/install.log（HDFS文件系统路径） . :复制到当前目录下<br>        hadoop fs -text :查看HDFS中的文件<br>        hadoop fs -rm :删除HDFS文件系统下的文件<br>        hadoop fs -rmr :递归删除HDFS文件系统下的文件盒文件夹<br>        hadoop fs -help:查看手册<br>        hadoop fs -ls hdfs:hadoop:9000/<br>        （2）RPC(remove process call)</p>
<pre><code>    命令：
    zcat *.gz &gt; abc.gz 把所有的以gz结尾的文件汇总放到一个文件abc文件里边
    eclipse安装路径：/root/Genuitec/MyEclipse-8.6
</code></pre>
<p><strong>二、hbase安装</strong><br><strong>(1)hbase-env.sh</strong><br>    export JAVA_HOME=/usr/java/jdk1.7.0_55<br><strong>(2)hbase-site.xml</strong><br>        <configuration><br>        <property><br>        <name>hbase.rootdir</name><br>        <value>hdfs://hadoop:9000/hbase</value><br>        </property><br>        </configuration><br><strong>(3)/usr/hbase-0.94.20/bin/start-hbase.sh(注意：要在hadoop启动的情况下启动hbase才能启动)</strong><br>        进入hbase命令模式：/usr/hbase-0.94.20/bin/目录下。<br>        hbase shell</p>
<p><strong>（4）hbase-env.sh</strong><br>        hbase与hadoop结合<br>        export HBASE_CLASSPATH=/usr/hadoop/conf（hadoop配置目录）<br><strong>（5）hbase-site.xml 打开分布模式</strong><br>        <property><br>        <name>hbase.cluster.distributed</name><br>        <value>true</value><br>        </property><br>        export HBASE_CLASSPATH=/usr/hadoop/conf<br>         regionservers中写入节点名字【默认是localhost】</p>
<pre><code>验证hbase安装成功
http://192.168.1.121:60010/master.jsp
</code></pre>
<p><strong>(6)hbase 的shell命令</strong><br>            1 status 查看状态<br>            2 version  查看hbase版本<br>            3 create ‘member’,’member_id’,’address’,’info’ 建表<br>                      表明      列族         列族     列族<br>            4 list 查看有那些表<br>            5 describe ‘member’ 查看表结构<br>            6 修改表结构<br>             alter ‘member’,{NAME=&gt;’member_id’,METHOD=&gt;’delete’}<br>            修改之前首先离线此表：disable ‘member’<br>            总结步骤：<br>            （1）disable ‘member’<br>            （2）alter ‘member’,{NAME=&gt;’member_id’,METHOD=&gt;’delete’}<br>            （3）enable ‘member’<br>            7 删除表<br>              disable ‘temp_table’<br>              drop ‘temp_table’<br>            8 检查一个表是否存在<br>              exists ‘member’<br>            9 判断表enable或disable<br>              is_enabled ‘member’<br>              is_disabled ‘member’<br>            10插入<br>                <img src="20151211133642653.png" alt="这里写图片描述"><br>                Put ‘member’,’name’,’info:age’,’24’<br>            11 查询<br>            Get ‘member’,’name’<br>            Get ‘member’,’name’,’info’<br>            Get ‘member’,’name’,’info:age’<br>            <img src="20151211133723437.png" alt="这里写图片描述"><br>            12 更新<br>            Put ‘member’,’name’,’info:age’,’24’<br>            13 通过时间戳来获取数据<br>                Get ‘member’,’name’,{COLUMN=&gt;’info:age’,TIMESTAMP=&gt;2532452345345}<br>            14 全表扫描<br>                Scan ‘member’<br>            15 删除某个字段<br>                Delete ‘member’,’name’,’info:age’<br>            16 删除整行<br>                Deleteall ‘member’,’xiaoming’<br>            17 查询表有多少行<br>                Count ‘member’<br>            18 清空一个表<br>                Truncate ‘member’<br>    Habase API<br>        <span class="exturl" data-url="aHR0cHM6Ly9oYmFzZS5hcGFjaGUub3JnL2FwaWRvY3MvaW5kZXguaHRtbA==">https://hbase.apache.org/apidocs/index.html<i class="fa fa-external-link-alt"></i></span></p>
<p><strong>三、pig的安装</strong><br>            1、 进入grunt shell<br>            Pig –x shell<br>            2 、pig 配置<br>                export PIG_HOME=/usr/pig-0.12.0<br>            export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$HBASE_HOME/bin:$PIG_HOME/bin:$PATH<br>            export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar<br>            export PIG_CLASSPATH=$HADOOP_HOME/conf/<br>            3、 启动pig<br>                Pig<br>            4、 常用命令<br>                Ls cd cat<br>            5、 复制文件到操作系统<br>            copyToLocal<br>            6、 执行操作系统命令<br>                Sh 进入操作系统命令状态<br>            7、  pig数据类型<br><img src="20151211134053215.png" alt="这里写图片描述"><br>            8、 pig Latin常用语句<br>            <img src="20151211134124883.png" alt="这里写图片描述"><br>            9、 举例<br>                 Records = LOAD ‘input/a/b/exe.txt’  AS  (year:chararray,temperature:int,quality:int);<br>                 变量                                抽象结构<br>            10 、展现<br>                Dump Records<br>    <img src="20151211134209802.png" alt="这里写图片描述"><br>            11、 查看结构<br>            Describe records<br>    <img src="20151211134249127.png" alt="这里写图片描述"><br>            12、 筛选<br>        (1)    Filtered_records = filter records by temperature !=9999 and (quality == 0 or quality == 4 or quality==5 or quality == 9);<br>        (2)    dump Filtered_records<br>        13 、group函数<br>             (1)Group_records = group filtered_records by year ;<br>             (2)Dump Group_records;<br><img src="20151211134326654.png" alt="这里写图片描述"><br>        14 、Max函数<br>            Max_temp = foreach grouped_records generate group ,max(filtered_records.tempetature);<br>        Dump Max_temp<br>        15、  函数<br>        (1)A =load  ‘input/grid/home/csdn.txt’  using  PigStorage(‘#’) as (id ,pw,em);<br>            (2)B = foreach A generate em;<br>            (3)Store B into ‘output/home/email.txt’  using PigStorage();</p>
<p><strong>四、hive的安装</strong><br>            hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>
<pre><code>        1、安装（http://blog.csdn.net/yfkiss/article/details/7721329）
        文件Hive/bin/hive-configsh末尾加入
        export JAVA_HOME=/usr/java/jdk1.7.0_55
        export HADOOP_HOME=/usr/hadoop
        export HIVE_HOME=/usr/hive
        2、搭建
            在hdfs上建目录：
         hadoop fs -mkdir /tmp
         hadoop fs -mkdir /user/hive/warehouse

        3、添加权限：
         hadoop fs -chmod g+w   /tmp
         hadoop fs -chmod g+w   /user/hive/warehouse

        4、下载解压hive：
         wget http://labs.mop.com/apache-mirror/hive/stable/hive-0.8.1.tar.gz .
         tar -zxvf hive-0.8.1.tar.gz
        5、设置HADOOP_HOME、HIVE_HOME
        export HADOOP_HOME=/home/zxm/hadoop/hadoop-1.0.3
        export HIVE_HOME=/home/work/hadoop/hive-0.8.1

        6、多用户支持
        (确认已安装好mysql)
        启动mysql：
        mysql -u root -p
        mysql&gt;grant all on hive.* to root@localhost identified by &#39;operater&#39;
        7、修改hive conf/hive-site.xml，如下：
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;  </span><br><span class="line">		  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;  </span><br><span class="line">		  &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&lt;alue&gt;  </span><br><span class="line">		  &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;  </span><br><span class="line">		&lt;/property&gt;  </span><br><span class="line">		&lt;property&gt;  </span><br><span class="line">		  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;  </span><br><span class="line">		  &lt;value&gt;com.mysql.jdbc.Driver&lt;alue&gt;  </span><br><span class="line">		  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;  </span><br><span class="line">		&lt;/property&gt;  </span><br><span class="line">		&lt;property&gt;  </span><br><span class="line">		  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;  </span><br><span class="line">		  &lt;value&gt;root&lt;alue&gt;  </span><br><span class="line">		  &lt;description&gt;username to use against metastore database&lt;/description&gt;  </span><br><span class="line">		&lt;/property&gt;  </span><br><span class="line">		&lt;property&gt;  </span><br><span class="line">		  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;  </span><br><span class="line">		  &lt;value&gt;operater&lt;alue&gt;  </span><br><span class="line">		  &lt;description&gt;password to use against metastore database&lt;/description&gt;  </span><br><span class="line">		&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">		&lt;property&gt;</span><br><span class="line">		  &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">		  &lt;!--&lt;value&gt;true&lt;/value&gt;--&gt;</span><br><span class="line">		  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">		   &lt;description&gt;</span><br><span class="line">		   Enforce metastore schema version consistency.</span><br><span class="line">		   True: Verify that version information stored in metastore matches with one from Hive jars.  Also disable automatic</span><br><span class="line">		         schema migration attempt. Users are required to manully migrate schema after Hive upgrade which ensures</span><br><span class="line">		         proper metastore schema migration. (Default)</span><br><span class="line">		   False: Warn if the version information stored in metastore doesn&#x27;t match with one from in Hive jars.</span><br><span class="line">		   &lt;/description&gt;</span><br><span class="line">		&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<pre><code>        8、下载mysql jdbc包：
        wget http://downloads.mysql.com/archives/mysql-connector-java-5.0/mysql-connector-java-5.0.8.tar.gz .
        解压：
        tar -zxvf mysql-connector-java-5.0.8.tar.gz
        将mysql-connector-java-5.0.8-bin.jar拷贝到hive lib目录下：
        cp mysql-connector-java-5.0.8/mysql-connector-java-5.0.8-bin.jar  ./lib
        9、启动hive：
        Cd  /usr/hive/bin
        ./hive
        10、测试
        Show tables;
</code></pre>
<p><strong>五、SQOOP的安装</strong></p>
<pre><code>        1.项目环境（http://blog.csdn.net/dhtz123456/article/details/12943833）
               项目用到的hadoop的版本是1.2.1，所以对应的sqoop是sqoop-1.4.4.bin__hadoop-1.0.0，mysql的jdbc是mysql-connector-java-5.1.24
        2.安装
             1).解压sqoop，配置环境变量：在/etc/profile中添加：
        export $SQOOP_HOME=/usr/sqoop
        export $PATH = $SQOOP_HOME/bin:$PATH
           2). 执行    source /etc/profile
        3. 复制集群中hadoop的core包以及mysql-jdbc包到sqoop-lib目录下。
        4. 配置home路径，conf/sqoop-env.sh下
        Set path to where bin/hadoop is available
        export HADOOP_COMMON_HOME=/usr/hadoop

        Set path to where hadoop-*-core.jar is available
        export HADOOP_MAPRED_HOME=/usr/hadoop

        set the path to where bin/hbase is available
        export HBASE_HOME=/usr/hbase-0.94.20

        Set the path to where bin/hive is available
        export HIVE_HOME=/home/hadoop/hive-0.11.0
        5 命令
        ![这里写图片描述](20151211134706254.png)
        从mysql导入数据的例子
        ![这里写图片描述](20151211134735349.png)
        导入到hbase命令
        ![这里写图片描述](20151211134815140.png)
        从oracle导入数据
        ![这里写图片描述](20151211134841352.png)
        ![这里写图片描述](20151211134910954.png)
</code></pre>
<p><strong>六、其他linux上的hadoop使用技巧与命令</strong><br>1、复制一台机器的上的hadoop到其他机器<br>    Scp  -rp  ./hadoop-0.20.2  grid@h1:/home/grid<br>2、awk命令<br>    输入：<br>    <img src="20151211135104291.png" alt="这里写图片描述"><br>    输出：<br>    <img src="20151211135133008.png" alt="这里写图片描述"><br>    找出含有rr的文件名：<br>    <img src="20151211135208891.png" alt="这里写图片描述"><br>利用AWK复制hadoop结点<br><img src="20151211135241062.png" alt="这里写图片描述"><br>或者把命令放到文件中然后执行文件：<br><img src="20151211135308637.png" alt="这里写图片描述"><br>知识点：<br>1、    awk和sed命令 功能很强大<br>2、    集群的实施<br><img src="20151211135343825.png" alt="这里写图片描述"><br>解决办法：<br><img src="20151211135419203.png" alt="这里写图片描述"><br>DNS软件： 推荐“bind”<br>创建用户<br>Sudo groupadd hadoop<br>Sudo useradd  –s  /bin/bash  -d  /home/grid  -m  grid  -g  hadoop  –G  admin<br>安装SSH<br>Sudo apt—get install ssh</p>
<p>SSH免密码登陆<br> Ssh –keygen  -t  dsa  -p  ‘’  -f  <del>/.ssh/id_dsa<br>秘钥复制<br>Scp  grid@h1:</del>/.ssh/id_dsa.pub ~/.ssh/h1_dsa.pub<br>Cat ~/.ssh/h1_dsa.pub  &gt;&gt; ~/.ssh/authorized_keys<br>修改masters加入主节点名称<br>修改slaves加入子节点</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>CeaserWang
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux%E6%90%AD%E5%BB%BA%E5%91%BD%E4%BB%A4/" title="hadoop(1.1.2)+hbase0.98+hive+pig+sqoop+mysql+vsftp+tomcat+linux搭建命令">https://ceaser.wang/2018/09/28/hadoop-1-1-2-hbase0-98-hive-pig-sqoop-mysql-vsftp-tomcat-linux搭建命令/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/hadoop-hbase-hive-pig-sqoop-mysql-vsftp-tomcat-linux/" rel="tag"><i class="fa fa-tag"></i> hadoop hbase hive pig sqoop mysql vsftp tomcat linux</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/09/28/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-10-%E9%80%82%E9%85%8D%E5%99%A8Adapter/" rel="prev" title="设计模式(10)-适配器Adapter">
                  <i class="fa fa-chevron-left"></i> 设计模式(10)-适配器Adapter
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/09/28/hadoop2-5-1-Hbase0-98%E5%AE%89%E8%A3%85/" rel="next" title="hadoop2.5.1+Hbase0.98安装">
                  hadoop2.5.1+Hbase0.98安装 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2015 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CeaserWang</span>
</div>
  <div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9tdXNlLw==">NexT.Muse</span>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":"forest","js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.11.0/dist/mermaid.min.js","integrity":"sha256-sVAx+v/Q7v0Q2xm5vN7h5ccSna6gaLREhG9sF8pKT6I="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script class="next-config" data-name="nprogress" type="application/json">{"enable":true,"spinner":true}</script>
  <script src="/js/third-party/nprogress.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"ryAR9bttS7fex1FPEPAylmmJ-gzGzoHsz","app_key":"dYqygoN4Y01Bl38OdRoCHUYn","server_url":null,"security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>



</body>
</html>
